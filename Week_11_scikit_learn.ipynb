{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Week 11 - scikit-learn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZahpWHCKfDmH",
        "TKjaW5A_kwDk",
        "dJ3cIuAflKZS",
        "m2nARHg5nr1n"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyalan/CUHK-STAT5106-2020/blob/main/Week_11_scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIkjTOSjhRay"
      },
      "source": [
        "Reference: [sklearn tutorial: Column Transformer with Mixed Types](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHTHrB7BYXfu"
      },
      "source": [
        "# Modelling Stage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Wl3LmdPUcGB"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjuOne3UUdxg"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI5xIHeHUkLb"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Load data from https://www.openml.org/d/40945\n",
        "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGWqE5zBfL_G"
      },
      "source": [
        "print(X.info())\n",
        "print(X.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAAZHzvJiwcp"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZahpWHCKfDmH"
      },
      "source": [
        "## Spliting Train-Dev-Test data\n",
        "\n",
        "[Reference](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKF-BITbfM9I"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "print(f'Train-Dev-Test data has been splited: ')\n",
        "print(f'Train set: {X_train.shape} , {y_train.shape}')\n",
        "print(f'Dev set: {X_dev.shape} , {y_dev.shape}')\n",
        "print(f'Test set: {X_test.shape} , {y_test.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKjaW5A_kwDk"
      },
      "source": [
        "## Set Regressor and Response Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lZG1axlkzD1"
      },
      "source": [
        "regressors_num = ['age', 'fare']\n",
        "regressors_cat = ['embarked', 'sex', 'pclass']\n",
        "response = 'survived'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ3cIuAflKZS"
      },
      "source": [
        "## Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPS23E5jnUDA"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "transformers_num = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median'))\n",
        "    , ('logtransformer', FunctionTransformer(np.log1p))\n",
        "    , ('scaler', StandardScaler())\n",
        "])\n",
        "transformers_cat = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', transformers_num, regressors_num),\n",
        "        ('cat', transformers_cat, regressors_cat)]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_VSXdTxnVqX"
      },
      "source": [
        "preprocessor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJc0f_aynZ91"
      },
      "source": [
        "# fit / transform with preprocessor\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_dev = preprocessor.transform(X_dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_RHM1fhpDa9"
      },
      "source": [
        "print(f'Train-Dev data has been transformed: ')\n",
        "print(f'Train set: {X_train.shape} , {y_train.shape}')\n",
        "print(f'Dev set: {X_dev.shape} , {y_dev.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2nARHg5nr1n"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXhhtt4OYXfu"
      },
      "source": [
        "# Logistic Regression Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_logReg = LogisticRegression()\n",
        "model_logReg.fit(X_train, y_train)\n",
        "print(f'Logistic Model Accuracy (train set) = {model_logReg.score(X_train, y_train)}')\n",
        "print(f'Logistic Model Accuracy (dev set) = {model_logReg.score(X_dev, y_dev)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sztbM26SogoF"
      },
      "source": [
        "# Decision Tree Model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model_dtree = DecisionTreeClassifier()\n",
        "model_dtree.fit(X_train, y_train)\n",
        "print(f'Decision Tree Model Accuracy (train set) = {model_dtree.score(X_train, y_train)}')\n",
        "print(f'Decision Tree Model Accuracy (dev set) = {model_dtree.score(X_dev, y_dev)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oeUtzbnps3b"
      },
      "source": [
        "Logistic Model is better in dev set performance. So...\n",
        "\n",
        "# Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HOpJI8Dp9OQ"
      },
      "source": [
        "model = model_logReg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oOUswLtqVVF"
      },
      "source": [
        "from joblib import dump, load\n",
        "dump(preprocessor, 'preprocessor.joblib')\n",
        "dump(model, 'model.joblib')\n",
        "\n",
        "print(os.listdir())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PPTOzfFq5q5"
      },
      "source": [
        "# Predicting Stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch-WX3Rbrs2o"
      },
      "source": [
        "## Load back materials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlKX4s3brv6o"
      },
      "source": [
        "# Load back the saves\n",
        "preprocessor_test = load('preprocessor.joblib')\n",
        "model_test = load('model.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTDXS_rIYXfu"
      },
      "source": [
        "X_test = preprocessor_test.transform(X_test)\n",
        "y_test_pred = model_test.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNAvXLSgp612"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}